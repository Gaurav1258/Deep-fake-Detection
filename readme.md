# DeepFake Detection using MesoNET Architecture
## Team Description
Gaurav Shrivastava 20BRS1036
Swapnal Varma 20BRS1123
Krishna Sarawagi 20BRS1115
Reddy Sairam Rajasekhar 20BRS1252
  
## Introduction:
##### What are deep fake videos? 
Deep Fake videos are videos that have been manipulated using artificial intelligence and machine learning techniques to alter or replace the appearance of a person in the video. The technology allows to superimpose the face of one person onto the body of another person in a video, making it almost indistinguishable from real videos.
The term “Deepfake” is a combination of “Deep Learning” and “Fake,” referring to the use of deep learning algorithms to generate highly realistic video manipulations. This technology uses a technique called “Face Swapping,” where a deep learning model is trained on a dataset of real videos and images of a person. The model learns the facial features, expressions, and movements of the person, and can then be used to generate new, fake videos of that person.
It is basically implemented using a type of neural network called a Generative Adversarial Network (GAN) or a Variational Autoencoder (VAE). These networks consist of two parts, a generator, and a discriminator. The generator takes in a random input, such as a random noise vector, and produces an output, such as an image or video. The discriminator is trained to differentiate between real and fake samples, and the generator is trained to produce samples that can fool the discriminator into thinking they are real.

##### History of deep fake videos: 
The history of this technology of deep fake videos can be traced back to the early 2000s, when researchers first began experimenting with the use of artificial intelligence and machine learning techniques to manipulate videos. However, at the time the technology was not advanced enough to be able to generate highly realistic results.
Then, in 2015 a researcher at the University of Washington developed a technique called “Face2Face” which used computer vision and machine learning to manipulate videos of people’s faces in real-time. This is considered as one of the first demonstrations of the potential for deepfake technology.
In 2016, a subreddit called “Deepfakes'' was created, which was dedicated to creating and sharing deepfake videos. This subreddit gained popularity very quickly and then the technology behind deepfakes began to spread very rapidly.
In 2017, researchers at Samsung’s Artificial Intelligence Center at Moscow published a paper that introduced a technique called “Deep Video Portraits”, which used deep learning to create highly realistic deep fake videos. This was a significant breakthrough in the field and marked the beginning of the era of high-quality deep fake videos. Then in 2018, this technology became widely known to the public.
Why are deep fake images or videos a problem? 
After 2018, when this technology was more widely known to the public, it raised concerns among the politicians, celebrities, and the general public. Many experts and politicians started to raise awareness of the dangers of deep fake technology and the need for laws and regulations to prevent its malicious use.
Many deep fake videos have been used for political propaganda, entertainment, and non-consensual pornographic content. The technology has advanced, and it has become easier and easier to create deep fake videos with time, which raises the concern about the malicious use of deep fake videos. Among many potential problems, some issues can be listed as (not exhaustive):

##### Misinformation and propaganda: 
Deep fake videos can be used to spread false information, manipulate public opinion, and influence political decisions. They can also be used to create fake news and propaganda that can be difficult to distinguish from real content.
Damage to reputations: Deep fake videos can be used to damage the reputations of individuals, organizations, and companies. They can be used to create videos that are totally fake of celebrities, politicians, or general public figures that can eventually be used to blackmail them or ruin their reputation.
 Non-consensual pornographic content: This technology can be used to create fake pornographic content of individuals without their consent which is a total exploitation and abuse.
 Legal and ethical implications: The use of deep fake technology raises serious legal and ethical questions. It is important to consider the potential harm that deep fake videos can cause, and to ensure that they are not used for malicious purposes.
Finally, we can say that it is very important to keep in our mind that just like any other technology, this technology of deep fake videos has the potential for many positive uses but at the same time it also has a number of potential risks and challenges, such as spreading misinformation and damaging reputations, therefore, the development of deep fake technology should be done in an ethical and responsible way. As the technology is advancing day by day, it is getting harder and harder to detect and prevent their use and its potential for harm also increases.
 
Because of this, in recent years researchers and many organizations have started to work on developing techniques that can detect deep fake videos, and many countries have started to develop laws and regulations to address the issue.

## DATASET:
### Training Set
To download the dataset you can follow the [link](https://www.kaggle.com/competitions/deepfake-detection-challenge/data) that will take you kaggle.com where you need to accept the terms and condition then you can download the dataset. This code competition's training set is not available directly on Kaggle, as its size is prohibitively large to train in Kaggle. Instead, it's strongly recommended that you train offline and load the externally trained model as an external dataset into Kaggle Notebooks to perform inference on the Test Set. Review Getting Started for more detailed information.

The full training set is just over 470 GB. Kaggle competition has made it available as one giant file, as well as 50 smaller files, each ~10 GB in size. You must accept the competition's rules to gain access for using the dataset.

Rather than downloading you can load your download your kaggle key which comes in a JSON format containing user specific key that can be used for loading any dataset in your personal cloud based platform like google colab.

### Files

train_sample_videos.zip - a ZIP file containing a sample set of training videos and a metadata.json with labels. the full set of training videos is available through the links provided above.

sample_submission.csv - a sample submission file in the correct format.

test_videos.zip - a zip file containing a small set of videos to be used as a public validation set.

To understand the datasets available for this competition, review the Getting Started information.

### Columns
filename - the filename of the video

label - whether the video is REAL or FAKE

original - in the case that a train set video is FAKE, the original video is listed here

split - this is always equal to "train".
